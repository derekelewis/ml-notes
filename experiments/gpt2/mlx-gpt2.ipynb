{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b9e576-26ba-4942-857d-6f45cfebcf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb46c703-486b-48b5-b083-23a5874a701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mx.array(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f077bb62-8664-4007-965e-2c127a92c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n",
      "(6, 6)\n",
      "(6, 3)\n",
      "attn_scores: array([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.631],\n",
      "       [0.9544, 1.495, 1.4754, 0.8434, 0.707, 1.0865],\n",
      "       [0.9422, 1.4754, 1.457, 0.8296, 0.7154, 1.0605],\n",
      "       [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "       [0.4576, 0.707, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "       [0.631, 1.0865, 1.0605, 0.6565, 0.2935, 0.945]], dtype=float32)\n",
      "attn_weights: array([[0.209835, 0.200581, 0.198149, 0.124228, 0.122049, 0.145158],\n",
      "       [0.138548, 0.237891, 0.233274, 0.123992, 0.108182, 0.158114],\n",
      "       [0.139008, 0.236921, 0.232602, 0.124204, 0.1108, 0.156464],\n",
      "       [0.143527, 0.207394, 0.204552, 0.146192, 0.126295, 0.172039],\n",
      "       [0.152611, 0.195839, 0.197491, 0.136687, 0.187859, 0.129514],\n",
      "       [0.138471, 0.218364, 0.212759, 0.142048, 0.0988064, 0.189552]], dtype=float32)\n",
      "context_vectors: array([[0.442059, 0.593099, 0.578989],\n",
      "       [0.441866, 0.651482, 0.568309],\n",
      "       [0.443128, 0.649595, 0.567073],\n",
      "       [0.43039, 0.629828, 0.551027],\n",
      "       [0.467102, 0.590993, 0.526597],\n",
      "       [0.417725, 0.650323, 0.564535]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = mx.zeros([inputs.shape[0], inputs.shape[0]])\n",
    "attn_weights = mx.zeros([inputs.shape[0], inputs.shape[0]])\n",
    "context_vectors = mx.zeros([inputs.shape[0], inputs.shape[1]])\n",
    "print(attn_scores.shape)\n",
    "print(attn_weights.shape)\n",
    "print(context_vectors.shape)\n",
    "\n",
    "for i, x in enumerate(inputs):\n",
    "    # calculate attention scores\n",
    "    for j, y in enumerate(inputs):\n",
    "        attn_scores[i, j] = mx.tensordot(x, y, 1)\n",
    "    # calculate attention weights\n",
    "    attn_weights[i] = mx.softmax(attn_scores[i])\n",
    "    # calculate context vectors\n",
    "    for j, y in enumerate(inputs):\n",
    "        context_vectors[i] += y * attn_weights[i, j]\n",
    "\n",
    "print(f\"attn_scores: {attn_scores}\")\n",
    "print(f\"attn_weights: {attn_weights}\")\n",
    "print(f\"context_vectors: {context_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03143603-6c13-42e9-9b2d-74d456cd3705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n",
      "(6, 6)\n",
      "(6, 3)\n",
      "attn_scores: array([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.631],\n",
      "       [0.9544, 1.495, 1.4754, 0.8434, 0.707, 1.0865],\n",
      "       [0.9422, 1.4754, 1.457, 0.8296, 0.7154, 1.0605],\n",
      "       [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "       [0.4576, 0.707, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "       [0.631, 1.0865, 1.0605, 0.6565, 0.2935, 0.945]], dtype=float32)\n",
      "attn_weights: array([[0.209835, 0.200581, 0.198149, 0.124228, 0.122049, 0.145158],\n",
      "       [0.138548, 0.237891, 0.233274, 0.123992, 0.108182, 0.158114],\n",
      "       [0.139008, 0.236921, 0.232602, 0.124204, 0.1108, 0.156464],\n",
      "       [0.143527, 0.207394, 0.204552, 0.146192, 0.126295, 0.172039],\n",
      "       [0.152611, 0.195839, 0.197491, 0.136687, 0.187859, 0.129514],\n",
      "       [0.138471, 0.218364, 0.212759, 0.142048, 0.0988064, 0.189552]], dtype=float32)\n",
      "context_vectors: array([[0.442059, 0.593099, 0.578989],\n",
      "       [0.441866, 0.651482, 0.568309],\n",
      "       [0.443128, 0.649595, 0.567073],\n",
      "       [0.43039, 0.629828, 0.551027],\n",
      "       [0.467102, 0.590993, 0.526596],\n",
      "       [0.417725, 0.650323, 0.564535]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = mx.zeros([inputs.shape[0], inputs.shape[0]])\n",
    "attn_weights = mx.zeros([inputs.shape[0], inputs.shape[0]])\n",
    "context_vectors = mx.zeros([inputs.shape[0], inputs.shape[1]])\n",
    "print(attn_scores.shape)\n",
    "print(attn_weights.shape)\n",
    "print(context_vectors.shape)\n",
    "\n",
    "attn_scores = inputs @ inputs.T\n",
    "attn_weights = mx.softmax(attn_scores, axis=-1)\n",
    "context_vectors = attn_weights @ inputs\n",
    "\n",
    "print(f\"attn_scores: {attn_scores}\")\n",
    "print(f\"attn_weights: {attn_weights}\")\n",
    "print(f\"context_vectors: {context_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d9a929-7406-4b84-b670-fbf6245f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6382887d-099e-4044-9cf0-d6379bfc502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in=inputs.shape[1]\n",
    "d_out=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30dc8b61-efbc-49df-b0c0-bc7fdc68ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.543625, -0.357191, -0.369193],\n",
      "       [0.180697, 0.397937, 0.478428]], dtype=float32)\n",
      "array([[0.539553, -0.131374, 0.397048],\n",
      "       [0.491569, -0.49601, -0.050792]], dtype=float32)\n",
      "array([[0.289075, -0.445376, -0.425039],\n",
      "       [0.186969, -0.275999, -0.539648]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W_query = nn.Linear(d_in, d_out, bias=False)\n",
    "W_key = nn.Linear(d_in, d_out, bias=False)\n",
    "W_value = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "print(W_query.weight)\n",
    "print(W_key.weight)\n",
    "print(W_value.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78e3f4e-338c-4bce-bd9c-776d225be060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries: array([[-0.61592, 0.563191],\n",
      "       [-0.853417, 0.761351],\n",
      "       [-0.849762, 0.747438],\n",
      "       [-0.448602, 0.428438],\n",
      "       [-0.544809, 0.286464],\n",
      "       [-0.51599, 0.59052]], dtype=float32)\n",
      "keys: array([[0.565675, 0.0917684],\n",
      "       [0.444511, -0.194688],\n",
      "       [0.449988, -0.173921],\n",
      "       [0.173531, -0.196302],\n",
      "       [0.422317, 0.249427],\n",
      "       [0.140255, -0.400165]], dtype=float32)\n",
      "values: array([[-0.320789, -0.44129],\n",
      "       [-0.509011, -0.493454],\n",
      "       [-0.485821, -0.473402],\n",
      "       [-0.334984, -0.29703],\n",
      "       [0.06874, 0.0210016],\n",
      "       [-0.575618, -0.508257]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "queries = W_query(inputs)\n",
    "keys = W_key(inputs)\n",
    "values = W_value(inputs)\n",
    "\n",
    "print(f\"queries: {queries}\")\n",
    "print(f\"keys: {keys}\")\n",
    "print(f\"values: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c395008-42dc-44fc-a81a-857209b05403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores: array([[-0.296727, -0.38343, -0.375107, -0.217436, -0.119639, -0.311755],\n",
      "       [-0.412889, -0.527579, -0.516443, -0.297549, -0.170512, -0.424362],\n",
      "       [-0.412098, -0.523246, -0.512378, -0.294183, -0.172439, -0.418282],\n",
      "       [-0.214446, -0.28282, -0.27638, -0.161949, -0.0825886, -0.234365],\n",
      "       [-0.281896, -0.297944, -0.29498, -0.150774, -0.15863, -0.191045],\n",
      "       [-0.237691, -0.344331, -0.334893, -0.20546, -0.0706202, -0.308676]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T\n",
    "print(f\"attn_scores: {attn_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2049f16-d1a8-4e89-886e-a796889c7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights: array([[0.164823, 0.155022, 0.155936, 0.174328, 0.18681, 0.163081],\n",
      "       [0.163523, 0.150785, 0.151977, 0.177419, 0.194094, 0.162202],\n",
      "       [0.163313, 0.150969, 0.152133, 0.177513, 0.193472, 0.1626],\n",
      "       [0.165796, 0.157971, 0.158692, 0.172066, 0.181998, 0.163477],\n",
      "       [0.160409, 0.158599, 0.158931, 0.175992, 0.175017, 0.171052],\n",
      "       [0.167773, 0.155587, 0.156629, 0.17164, 0.188811, 0.15956]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = mx.softmax(attn_scores / keys.shape[-1]**0.5, axis=-1)\n",
    "print(f\"attn_weights: {attn_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbb1353-2d85-4cf7-9e93-73a82ae26950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6, dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.sum(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6cf3909-d3f8-46fc-8f69-ac65f9a96463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vectors: array([[-0.346966, -0.353796],\n",
      "       [-0.342498, -0.349576],\n",
      "       [-0.342904, -0.349891],\n",
      "       [-0.34992, -0.356615],\n",
      "       [-0.354782, -0.359824],\n",
      "       [-0.345472, -0.353074]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "context_vectors = attn_weights @ values\n",
    "print(f\"context_vectors: {context_vectors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c107c7c-e946-4a67-98e8-12c9c264bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = mx.softmax(attn_scores / keys.shape[-1] ** 0.5, axis=-1)\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24a1dc96-ccfa-4b3d-95c7-003454285d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.0318105, 0.37613],\n",
      "       [0.0256262, 0.370863],\n",
      "       [0.0256772, 0.370911],\n",
      "       [0.0355207, 0.379327],\n",
      "       [0.0324242, 0.376756],\n",
      "       [0.0343046, 0.378258]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(789)\n",
    "sav1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sav1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999c725e-30e2-4f58-b8e0-ec47ed125d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "batch = mx.stack((inputs, inputs), 0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc984ed6-c841-4db0-abd2-117b409f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        mask = nn.MultiHeadAttention.create_additive_causal_mask(num_tokens)\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.transpose(0, 2, 1)\n",
    "        attn_scores = attn_scores + mask\n",
    "        attn_weights = mx.softmax(attn_scores / keys.shape[-1] ** 0.5, axis=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cee1f0d-4080-4318-ab43-7063b4dfebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-0.320789, -0.44129],\n",
      "        [-0.411086, -0.466315],\n",
      "        [-0.435542, -0.468648],\n",
      "        [-0.409961, -0.423741],\n",
      "        [-0.309213, -0.329195],\n",
      "        [-0.345472, -0.353074]],\n",
      "       [[-0.320789, -0.44129],\n",
      "        [-0.411086, -0.466315],\n",
      "        [-0.435542, -0.468648],\n",
      "        [-0.409961, -0.423741],\n",
      "        [-0.309213, -0.329195],\n",
      "        [-0.345472, -0.353074]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "context_size = 6\n",
    "dropout = 0.0\n",
    "ca = CausalAttention(d_in,d_out,context_size,dropout)\n",
    "print(ca(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137a7043-428c-4587-913b-95296c337cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "                      for _ in range(num_heads)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return mx.concatenate([head(x) for head in self.heads], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee540c71-fa19-4ac5-ba68-e8d4ea587036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-0.320789, -0.44129, -0.29132, -0.473982],\n",
      "        [-0.411086, -0.466315, -0.293595, -0.425057],\n",
      "        [-0.435542, -0.468648, -0.287361, -0.410947],\n",
      "        [-0.409961, -0.423741, -0.265774, -0.343301],\n",
      "        [-0.309213, -0.329195, -0.184421, -0.354609],\n",
      "        [-0.345472, -0.353074, -0.22734, -0.305751]],\n",
      "       [[-0.320789, -0.44129, -0.29132, -0.473982],\n",
      "        [-0.411086, -0.466315, -0.293595, -0.425057],\n",
      "        [-0.435542, -0.468648, -0.287361, -0.410947],\n",
      "        [-0.409961, -0.423741, -0.265774, -0.343301],\n",
      "        [-0.309213, -0.329195, -0.184421, -0.354609],\n",
      "        [-0.345472, -0.353074, -0.22734, -0.305751]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_size, dropout, 2)\n",
    "print(mha(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b274e9b6-a6b5-4944-9017-d8cac050f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj  = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        mask = nn.MultiHeadAttention.create_additive_causal_mask(num_tokens)\n",
    "        \n",
    "        # W(x):\n",
    "        # (d_in, d_out) @ (b, num_tokens, d_in) -> (b, num_tokens, d_out)\n",
    "        # or\n",
    "        # Wx:\n",
    "        # (d_in, d_out) @ ((b, num_tokens, d_in) -> (b, d_in, num_tokens))\n",
    "        # -> (b, d_out, num_tokens) -> (b, num_tokens, d_out)\n",
    "        #foo = W_query.weight @ x.transpose(0, 2, 1)\n",
    "        #foo = foo.transpose(0, 2, 1)\n",
    "        #print(foo)\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        #print(f\"queries before reshape: {queries}\")\n",
    "        #print(f\"queries shape before reshape: {queries.shape}\")\n",
    "        # b, num_tokens, d_out -> b, num_tokens, num_heads, head_dim\n",
    "        queries = queries.reshape(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        #print(f\"queries after reshape: {queries}\")\n",
    "        #print(f\"queries shape after reshape: {queries.shape}\")\n",
    "        # b, num_tokens, d_out -> b, num_tokens, num_heads, head_dim\n",
    "        keys = keys.reshape(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        # b, num_tokens, d_out -> b, num_tokens, num_heads, head_dim\n",
    "        values = values.reshape(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        queries = queries.transpose(0, 2, 1, 3) # b, num_heads, num_tokens, head_dim\n",
    "        keys = keys.transpose(0, 2, 1, 3) # b, num_heads, num_tokens, head_dim\n",
    "        values = values.transpose(0, 2, 1, 3) # b, num_heads, num_tokens, head_dim\n",
    "\n",
    "        # (b, num_heads, num_tokens, head_dim) @ (b, num_heads, head_dim, num_tokens)\n",
    "        # -> (b, num_heads, num_tokens, num_tokens)\n",
    "        attn_scores = queries @ keys.transpose(0, 1, 3, 2)\n",
    "        #print(f\"attn_scores shape: {attn_scores.shape}\")\n",
    "        # applied to each head\n",
    "        attn_scores = attn_scores + mask\n",
    "        # applied to each head\n",
    "        attn_weights = mx.softmax(attn_scores / keys.shape[-1] ** 0.5, axis=-1)\n",
    "        #print(f\"attn_weights: {attn_weights}\")\n",
    "        #print(f\"attn_weights shape: {attn_weights.shape}\")\n",
    "        # applied to each head\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # (b, num_heads, num_tokens, num_tokens) @ (b, num_heads, num_tokens, head_dim)\n",
    "        # -> (b, num_heads, num_tokens, head_dim) -> (b, num_tokens, num_heads, head_dim)\n",
    "        context_vectors = (attn_weights @ values).transpose(0, 2, 1, 3)\n",
    "        #print(f\"context_vectors shape: {context_vectors.shape}\")\n",
    "        context_vectors = context_vectors.reshape(b, num_tokens, self.d_out)\n",
    "        #print(f\"context_vectors reshape shape: {context_vectors.shape}\")\n",
    "        context_vectors = self.out_proj(context_vectors)\n",
    "        return context_vectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c3d2d8a-7405-4cba-bdd4-81b3a70afc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[0.409174, 0.713412],\n",
      "        [0.386287, 0.749947],\n",
      "        [0.377017, 0.775004],\n",
      "        [0.373301, 0.785103],\n",
      "        [0.372671, 0.790298],\n",
      "        [0.38174, 0.792961]],\n",
      "       [[0.409174, 0.713412],\n",
      "        [0.386287, 0.749947],\n",
      "        [0.377017, 0.775004],\n",
      "        [0.373301, 0.785103],\n",
      "        [0.372671, 0.790298],\n",
      "        [0.38174, 0.792961]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "mha = MultiHeadAttention(d_in=3, d_out=2, context_length=context_size, dropout=dropout, num_heads=2)\n",
    "print(mha(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeb40811-1525-43fc-9310-7342bcd1a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1cce8d3-43f5-44fb-a81a-92b689db73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def __call__(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(in_idx)\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "049b1fd5-ea07-45d3-a306-871cf2597519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyGPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0)\n",
      "  (trf_blocks): Sequential(\n",
      "    (layers.0): DummyTransformerBlock()\n",
      "    (layers.1): DummyTransformerBlock()\n",
      "    (layers.2): DummyTransformerBlock()\n",
      "    (layers.3): DummyTransformerBlock()\n",
      "    (layers.4): DummyTransformerBlock()\n",
      "    (layers.5): DummyTransformerBlock()\n",
      "    (layers.6): DummyTransformerBlock()\n",
      "    (layers.7): DummyTransformerBlock()\n",
      "    (layers.8): DummyTransformerBlock()\n",
      "    (layers.9): DummyTransformerBlock()\n",
      "    (layers.10): DummyTransformerBlock()\n",
      "    (layers.11): DummyTransformerBlock()\n",
      "  )\n",
      "  (final_norm): DummyLayerNorm()\n",
      "  (out_head): Linear(input_dims=768, output_dims=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01888b36-1d5b-4959-9772-d5acccccd846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[6109, 3626, 6100, 345],\n",
      "       [6109, 1110, 6622, 257]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(mx.array(tokenizer.encode(txt1)))\n",
    "batch.append(mx.array(tokenizer.encode(txt2)))\n",
    "batch = mx.stack(batch, 0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed99a98-db78-4158-9580-9048d1f8c7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: (2, 4, 50257)\n",
      "array([[[0.0267821, 0.0155803, 0.0453118, ..., -0.0255345, -0.00809556, 0.00276685],\n",
      "        [-0.0111713, 0.000690083, 0.00707004, ..., 0.049819, -0.015654, 0.0250585],\n",
      "        [0.0376061, 0.000597336, 0.0115421, ..., 0.0217559, 0.00157742, 0.0142852],\n",
      "        [-0.0245741, -0.00587755, -0.0392182, ..., 0.0260377, 0.0335556, -0.0157044]],\n",
      "       [[0.0267821, 0.0155803, 0.0453118, ..., -0.0255345, -0.00809556, 0.00276685],\n",
      "        [-0.0079119, 0.0182537, 0.015258, ..., -0.0132906, -0.0449415, 0.00437768],\n",
      "        [0.0288839, -0.0181241, -0.00847724, ..., -0.0113709, 0.0126249, -0.00459235],\n",
      "        [-0.0185885, -0.0469349, 0.00496355, ..., 0.00933472, -0.0203806, 0.0187356]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Outputs shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6dd6110-de5f-4ee2-bfc8-aa97e5f560dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = mx.ones((1, emb_dim)) # need to figure out how to make trainable parameter\n",
    "        self.shift = mx.zeros((1, emb_dim)) # need to figure out how to make trainable parameter\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mean = x.mean(axis=-1, keepdims=True)\n",
    "        var = x.var(axis=-1, keepdims=True)\n",
    "        norm_x = (x - mean) / mx.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f1c22d-7d0a-47e3-9af7-c6bac474b33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-1.19209e-08],\n",
      "       [-3.57628e-08]], dtype=float32)\n",
      "array([[0.999989],\n",
      "       [0.999989]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_example = mx.random.normal([2, 5])\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(axis=-1, keepdims=True)\n",
    "var = out_ln.var(axis=-1, keepdims=True)\n",
    "print(mean)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23d3dec2-9732-4fa2-8034-3d6ffec80f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return 0.5 * x * (1 + mx.tanh(\n",
    "            mx.sqrt(mx.array(2.0 / mx.pi)) *\n",
    "            (x + 0.044715 * mx.power(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72ac507f-75f1-46ed-b9fe-1da5ad382962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.841192, dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu = GELU()\n",
    "gelu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26699329-1be7-4c89-84ce-88aa674ed0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30cee70a-e998-4c3f-b255-af575bafa06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-0.0544744, 0.0381818, 0.100466, ..., -0.0528314, 0.397373, -0.0204547],\n",
      "        [0.00997397, -0.144488, -0.184294, ..., -0.392208, 0.202146, 0.156895],\n",
      "        [0.0389329, 0.0107757, 0.216761, ..., -0.179308, -0.224197, -0.0595259]],\n",
      "       [[-0.195685, -0.289583, 0.171215, ..., 0.208507, 0.0598475, 0.117642],\n",
      "        [-0.00110584, 0.0251188, 0.00942689, ..., 0.0129131, -0.0736913, 0.143136],\n",
      "        [0.0868328, 0.283533, 0.109481, ..., 0.126102, 0.0610082, -0.05509]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = mx.random.normal([2, 3, 768])\n",
    "out = ffn(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f8af3d9-439e-439b-8f4a-29f1058dff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06660af8-f495-4c94-8d5b-6595fe5593af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 4, 768)\n",
      "Output shape: (2, 4, 768)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "x = mx.random.normal([2, 4, 768])\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    " \n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4779dc0e-0003-42d7-8ec9-789a3547e296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-0.0782003, 0.987442, -0.94922, ..., 0.229853, -0.141867, -0.0107715],\n",
      "        [1.01852, 1.36634, 0.335559, ..., -0.409853, -0.265894, 1.22219],\n",
      "        [-1.2842, -0.0756759, -0.0471307, ..., -0.331826, 0.380631, 0.966117],\n",
      "        [-0.271844, -0.407028, 0.713517, ..., -0.857271, -1.33917, -1.52331]],\n",
      "       [[-1.36221, 2.13323, -0.0549182, ..., -0.124698, -0.573453, 0.370974],\n",
      "        [-0.977188, 0.941463, -1.4587, ..., -0.751929, 0.145659, -1.06629],\n",
      "        [-0.417758, -0.636303, -0.488185, ..., 0.147002, 0.342525, -0.617717],\n",
      "        [0.230238, -0.789932, 1.51675, ..., 0.74364, 0.210596, -1.63052]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f6f4016-f153-4aaa-8037-1f4d84c463a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def __call__(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(mx.arange(seq_len))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6f1fdb4-db03-4b50-9c11-ec03d3d7316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " array([[6109, 3626, 6100, 345],\n",
      "       [6109, 1110, 6622, 257]], dtype=int32)\n",
      "\n",
      "Output shape: (2, 4, 50257)\n",
      "array([[[-0.294867, 0.121118, -0.106109, ..., 0.328127, 0.382442, -0.200526],\n",
      "        [0.00421821, -0.0701152, -0.0358834, ..., -0.215521, 0.312019, -0.64688],\n",
      "        [-0.184812, -0.0243292, -0.129321, ..., -0.0671608, 0.421177, -0.480935],\n",
      "        [-0.423911, -0.150163, -0.359892, ..., 0.0569235, 0.144322, -0.833008]],\n",
      "       [[-0.294867, 0.121118, -0.106109, ..., 0.328127, 0.382442, -0.200526],\n",
      "        [-0.0484023, -0.301322, -0.0913256, ..., 0.13583, 0.371111, -0.635227],\n",
      "        [-0.205792, -0.286355, -0.177945, ..., 0.400727, 0.694369, -0.803182],\n",
      "        [-0.0800309, -0.236314, -0.479477, ..., 0.254939, 0.8567, -1.07093]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    " \n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17d06b7b-5a1c-4f55-87ef-fb7c3438faa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: (50257, 768)\n",
      "Output layer shape: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85e58fdb-6636-4361-91c9-ecd007a2b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        logits = model(idx_cond)\n",
    "       \n",
    "        logits = logits[:, -1, :]\n",
    "        probas = mx.softmax(logits, axis=-1)\n",
    "        idx_next = mx.argmax(probas, axis=-1, keepdims=True)\n",
    "        idx = mx.concatenate((idx, idx_next), axis=1)\n",
    " \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1f9298d-9fea-4692-9e99-fab4a5aaf5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = mx.expand_dims(mx.array(encoded), 0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7f82606-00ab-4580-997a-99c2a1b420e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: array([[15496, 11, 314, ..., 7646, 7646, 29160]], dtype=int64)\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5358b6a1-0248-43c8-9a10-8527a9796c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am strict strict strict strict strictwagen\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0385984e-8a1e-416b-afe1-eb2180b2fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.09999999999999998)\n",
       "  (trf_blocks): Sequential(\n",
       "    (layers.0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_key): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (W_value): Linear(input_dims=768, output_dims=768, bias=False)\n",
       "        (out_proj): Linear(input_dims=768, output_dims=768, bias=True)\n",
       "        (dropout): Dropout(p=0.09999999999999998)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (layers.0): Linear(input_dims=768, output_dims=3072, bias=True)\n",
       "          (layers.1): GELU()\n",
       "          (layers.2): Linear(input_dims=3072, output_dims=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.09999999999999998)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(input_dims=768, output_dims=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "mx.random.seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbf9efea-edb2-4caf-b1b3-8577cb76e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you DMVSK DMVieversseparSKseparseparseparsepar\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = mx.expand_dims(mx.array(encoded), 0) # add batch dimension\n",
    "    return encoded_tensor\n",
    " \n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    " \n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    " \n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75f5751c-7708-4575-9ec8-e88124933946",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"shakespeare.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f19eeccb-9d2b-4a8e-a6a8-a645ad3cc3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 94275\n",
      "Tokens: 25284\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61233497-f8cb-409f-b0fd-81eb4d996414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cee69c1d-0261-437b-8c81-d2910552fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=0)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0044da36-29c8-483a-9dea-4b14f59662cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    " \n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=False\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1493271f-8e8c-478e-a409-18e3f4e6b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "THE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "From fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thy self thy foe, to thy sweet self too cruel:\n",
      "Thou that art now the world's fresh ornament,\n",
      "And only herald to the gaudy spring,\n",
      "Within thine own bud buriest thy content,\n",
      "And tender churl mak'st waste in niggarding:\n",
      "Pity the world, or else this glutton be,\n",
      "To eat the world's due, by the grave and thee.\n",
      "\n",
      "When forty winters shall besiege thy brow,\n",
      "And dig deep trenches in thy beauty's field,\n",
      "Thy youth's proud livery so gazed on now,\n",
      "Will be a tattered weed of small worth held:  \n",
      "Then being asked, where all thy beauty lies,\n",
      "Where all the treasure of thy lusty days;\n",
      "To say within thine own deep sunken\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    " \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "samples = next(iter(train_loader))\n",
    "sample = samples[0][0]\n",
    "text = tokenizer.decode(sample.tolist())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd6b8419-5d17-49dc-954f-53ada4215fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_loss_batch(model, input_batch, target_batch):\n",
    "    input_batch, target_batch = input_batch, target_batch\n",
    "    logits = model(input_batch)\n",
    "    mlx_logits = logits.flatten(0, 1)\n",
    "    mlx_target_batch = target_batch.flatten()\n",
    "    #print(\"mlx_logits shape:\", mlx_logits.shape)\n",
    "    #print(\"mlx_target_batch shape:\", mlx_target_batch.shape)\n",
    "    mlx_loss = nn.losses.cross_entropy(\n",
    "        mlx_logits, mlx_target_batch, reduction='mean'\n",
    "    )\n",
    "    pytorch_logits = torch.tensor(np.array(logits)).flatten(0, 1)\n",
    "    pytorch_target_batch = torch.tensor(np.array(target_batch)).flatten()\n",
    "    #print(\"pytorch_logits shape:\", pytorch_logits.shape)\n",
    "    #print(\"pytorch_target_batch shape:\", pytorch_target_batch.shape)\n",
    "    pytorch_loss = torch.nn.CrossEntropyLoss()\n",
    "    pytorch_loss_output = pytorch_loss(pytorch_logits, pytorch_target_batch)\n",
    "    #print(\"mlx_loss:\", mlx_loss)\n",
    "    #print(\"pytorch_loss:\", pytorch_loss_output)\n",
    "    return mlx_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c42b445b-449e-4158-906e-c049fd197766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(model, mx.array(input_batch.numpy()), mx.array(target_batch.numpy()))\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51762dbb-b372-486c-8af1-ed49dcfd85bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(11.0006, dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_loss_batch(model, mx.array(samples[0].numpy()), mx.array(samples[1].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b9e8814-3e6d-4190-b9c6-80f98b3f5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.960246714678677\n",
      "Validation loss: 10.9336727142334\n"
     ]
    }
   ],
   "source": [
    "train_loss = calc_loss_loader(train_loader, model)\n",
    "val_loss = calc_loss_loader(val_loader, model)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c931e52-0d19-4db4-b87c-83c5294e3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    loss_and_grad_fn = nn.value_and_grad(model, calc_loss_batch)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            input_batch = mx.array(input_batch.numpy())\n",
    "            target_batch = mx.array(target_batch.numpy())\n",
    "            loss, grads = loss_and_grad_fn(model, input_batch, target_batch)\n",
    "            optimizer.update(model, grads)\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "            \n",
    "            tokens_seen += input_batch.size\n",
    "            global_step += 1\n",
    " \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    " \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1282568f-beb3-4081-8338-3719e3fba2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, eval_iter):\n",
    "    model.eval()\n",
    "    train_loss = calc_loss_loader(train_loader, model, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e82bd7d1-84cc-4eb7-9f07-8c84ce76a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer)\n",
    "    token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "    )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f600049b-e0a3-43cd-91c6-e4f66ff17a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 256, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False}\n",
      "Ep 1 (Step 000000): Train loss 11.001, Val loss 10.875\n",
      "Ep 1 (Step 000005): Train loss 9.248, Val loss 9.246\n",
      "Ep 1 (Step 000010): Train loss 8.535, Val loss 8.577\n",
      "Ep 1 (Step 000015): Train loss 7.472, Val loss 7.611\n",
      "Ep 1 (Step 000020): Train loss 6.588, Val loss 6.897\n",
      "Ep 1 (Step 000025): Train loss 6.357, Val loss 6.791\n",
      "Ep 1 (Step 000030): Train loss 6.366, Val loss 6.789\n",
      "Ep 1 (Step 000035): Train loss 6.232, Val loss 6.627\n",
      "Ep 1 (Step 000040): Train loss 6.295, Val loss 6.530\n",
      "Every effort moves you,  , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "Ep 2 (Step 000045): Train loss 6.058, Val loss 6.399\n",
      "Ep 2 (Step 000050): Train loss 5.781, Val loss 6.481\n",
      "Ep 2 (Step 000055): Train loss 5.856, Val loss 6.458\n",
      "Ep 2 (Step 000060): Train loss 6.102, Val loss 6.459\n",
      "Ep 2 (Step 000065): Train loss 6.181, Val loss 6.501\n",
      "Ep 2 (Step 000070): Train loss 6.229, Val loss 6.541\n",
      "Ep 2 (Step 000075): Train loss 6.215, Val loss 6.479\n",
      "Ep 2 (Step 000080): Train loss 6.180, Val loss 6.426\n",
      "Ep 2 (Step 000085): Train loss 6.120, Val loss 6.322\n",
      "Every effort moves you,                                                 \n",
      "Ep 3 (Step 000090): Train loss 5.839, Val loss 6.319\n",
      "Ep 3 (Step 000095): Train loss 5.601, Val loss 6.339\n",
      "Ep 3 (Step 000100): Train loss 5.629, Val loss 6.320\n",
      "Ep 3 (Step 000105): Train loss 5.760, Val loss 6.269\n",
      "Ep 3 (Step 000110): Train loss 5.846, Val loss 6.254\n",
      "Ep 3 (Step 000115): Train loss 5.902, Val loss 6.277\n",
      "Ep 3 (Step 000120): Train loss 5.895, Val loss 6.222\n",
      "Ep 3 (Step 000125): Train loss 5.903, Val loss 6.228\n",
      "Ep 3 (Step 000130): Train loss 5.901, Val loss 6.171\n",
      "Every effort moves you, And, And, And, And, And, And, And,, And, And, And, And, And, And, And, And, And,\n",
      "Ep 4 (Step 000135): Train loss 5.629, Val loss 6.163\n",
      "Ep 4 (Step 000140): Train loss 5.522, Val loss 6.183\n",
      "Ep 4 (Step 000145): Train loss 5.544, Val loss 6.176\n",
      "Ep 4 (Step 000150): Train loss 5.642, Val loss 6.196\n",
      "Ep 4 (Step 000155): Train loss 5.686, Val loss 6.195\n",
      "Ep 4 (Step 000160): Train loss 5.733, Val loss 6.195\n",
      "Ep 4 (Step 000165): Train loss 5.751, Val loss 6.164\n",
      "Ep 4 (Step 000170): Train loss 5.763, Val loss 6.143\n",
      "Ep 4 (Step 000175): Train loss 5.789, Val loss 6.114\n",
      "Every effort moves you, And to, And, And, And, And, And to, And to, And to to, And to, And, And, And to, And, And to\n",
      "Ep 5 (Step 000180): Train loss 5.530, Val loss 6.087\n",
      "Ep 5 (Step 000185): Train loss 5.455, Val loss 6.107\n",
      "Ep 5 (Step 000190): Train loss 5.442, Val loss 6.095\n",
      "Ep 5 (Step 000195): Train loss 5.480, Val loss 6.102\n",
      "Ep 5 (Step 000200): Train loss 5.541, Val loss 6.139\n",
      "Ep 5 (Step 000205): Train loss 5.583, Val loss 6.159\n",
      "Ep 5 (Step 000210): Train loss 5.628, Val loss 6.144\n",
      "Ep 5 (Step 000215): Train loss 5.641, Val loss 6.165\n",
      "Every effort moves you, And I I I I I I I I I I I I I I I, And, And I I I I I I, And, And I I I I I I I I, And I I I\n",
      "Ep 6 (Step 000220): Train loss 5.632, Val loss 6.126\n",
      "Ep 6 (Step 000225): Train loss 5.440, Val loss 6.137\n",
      "Ep 6 (Step 000230): Train loss 5.367, Val loss 6.128\n",
      "Ep 6 (Step 000235): Train loss 5.324, Val loss 6.066\n",
      "Ep 6 (Step 000240): Train loss 5.387, Val loss 6.115\n",
      "Ep 6 (Step 000245): Train loss 5.407, Val loss 6.138\n",
      "Ep 6 (Step 000250): Train loss 5.431, Val loss 6.089\n",
      "Ep 6 (Step 000255): Train loss 5.521, Val loss 6.139\n",
      "Ep 6 (Step 000260): Train loss 5.537, Val loss 6.116\n",
      "Every effort moves you, And I I I I I I I I I I I I I I I I I I I Ioth I I I Ioth I I I I I Ioth I, And I I I I I I I I I I\n",
      "Ep 7 (Step 000265): Train loss 5.430, Val loss 6.131\n",
      "Ep 7 (Step 000270): Train loss 5.266, Val loss 6.094\n",
      "Ep 7 (Step 000275): Train loss 5.199, Val loss 6.093\n",
      "Ep 7 (Step 000280): Train loss 5.358, Val loss 6.126\n",
      "Ep 7 (Step 000285): Train loss 5.275, Val loss 6.199\n",
      "Ep 7 (Step 000290): Train loss 5.334, Val loss 6.177\n",
      "Ep 7 (Step 000295): Train loss 5.369, Val loss 6.100\n",
      "Ep 7 (Step 000300): Train loss 5.393, Val loss 6.136\n",
      "Ep 7 (Step 000305): Train loss 5.425, Val loss 6.118\n",
      "Every effort moves you,  And I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I\n",
      "Ep 8 (Step 000310): Train loss 5.288, Val loss 6.124\n",
      "Ep 8 (Step 000315): Train loss 5.148, Val loss 6.092\n",
      "Ep 8 (Step 000320): Train loss 5.137, Val loss 6.089\n",
      "Ep 8 (Step 000325): Train loss 5.267, Val loss 6.119\n",
      "Ep 8 (Step 000330): Train loss 5.216, Val loss 6.158\n",
      "Ep 8 (Step 000335): Train loss 5.225, Val loss 6.193\n",
      "Ep 8 (Step 000340): Train loss 5.343, Val loss 6.176\n",
      "Ep 8 (Step 000345): Train loss 5.411, Val loss 6.155\n",
      "Ep 8 (Step 000350): Train loss 5.382, Val loss 6.186\n",
      "Every effort moves you, And I I love, And I I I theoth I I I theoth I I theoth I I I I I I I I theoth I I love, And I I theoth I I theoth I theoth\n",
      "Ep 9 (Step 000355): Train loss 5.215, Val loss 6.184\n",
      "Ep 9 (Step 000360): Train loss 5.095, Val loss 6.151\n",
      "Ep 9 (Step 000365): Train loss 5.067, Val loss 6.164\n",
      "Ep 9 (Step 000370): Train loss 5.131, Val loss 6.132\n",
      "Ep 9 (Step 000375): Train loss 5.120, Val loss 6.146\n",
      "Ep 9 (Step 000380): Train loss 5.238, Val loss 6.343\n",
      "Ep 9 (Step 000385): Train loss 5.314, Val loss 6.258\n",
      "Ep 9 (Step 000390): Train loss 5.383, Val loss 6.194\n",
      "Ep 9 (Step 000395): Train loss 5.297, Val loss 6.192\n",
      "Every effort moves you, And the'And the'And the'And the'And the''And the'And the''And the'And the''And the'''''And the'And the''''And I\n",
      "Ep 10 (Step 000400): Train loss 5.113, Val loss 6.257\n",
      "Ep 10 (Step 000405): Train loss 5.029, Val loss 6.206\n",
      "Ep 10 (Step 000410): Train loss 5.018, Val loss 6.153\n",
      "Ep 10 (Step 000415): Train loss 5.066, Val loss 6.163\n",
      "Ep 10 (Step 000420): Train loss 5.054, Val loss 6.178\n",
      "Ep 10 (Step 000425): Train loss 5.102, Val loss 6.300\n",
      "Ep 10 (Step 000430): Train loss 5.199, Val loss 6.325\n",
      "Ep 10 (Step 000435): Train loss 5.232, Val loss 6.206\n",
      "Every effort moves you,                                                 \n"
     ]
    }
   ],
   "source": [
    "import mlx.optimizers as optim\n",
    "\n",
    "print(GPT_CONFIG_124M)\n",
    "mx.random.seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "mx.eval(model.parameters())\n",
    "optimizer = optim.AdamW(learning_rate=optim.linear_schedule(0.0, 0.0002, 50), weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af13880c-3f36-4aa5-bc01-553ec5b54e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162419712\n"
     ]
    }
   ],
   "source": [
    "from mlx.utils import tree_flatten\n",
    "num_params = sum(v.size for _, v in tree_flatten(model.parameters()))\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbabb5c6-9ef2-4f2a-abbf-900c6702e4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    " \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5504f-f462-4d96-9973-7425e7fb7fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
